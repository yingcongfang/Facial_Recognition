#Cluster properties
#Sat Mar 20 19:42:33 PDT 2021
dataproc\:dataproc.scheduler.max-concurrent-jobs=5
yarn-env\:YARN_NODEMANAGER_HEAPSIZE=768
dataproc\:dataproc.heartbeat.worker.frequency.sec=-1
mapred\:mapreduce.reduce.cpu.vcores=1
dataproc\:agent.spark.driver.empty.jar=true
dataproc\:dataproc.control.task.request.interval.millis=5000
distcp\:mapreduce.map.java.opts=-Xmx576m
hadoop-env\:HADOOP_DATANODE_OPTS=-Xmx512m
spark-env\:SPARK_DAEMON_MEMORY=1920m
spark\:spark.executor.cores=1
mapred\:yarn.app.mapreduce.am.resource.mb=3072
hdfs\:dfs.namenode.service.handler.count=10
yarn\:yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs=86400
hdfs\:dfs.namenode.secondary.http-address=0.0.0.0\:9868
mapred\:yarn.app.mapreduce.am.resource.cpu-vcores=1
mapred\:yarn.app.mapreduce.am.command-opts=-Xmx2457m
mapred\:mapreduce.reduce.memory.mb=3072
mapred\:mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
spark\:spark.executorEnv.OPENBLAS_NUM_THREADS=1
mapred\:mapreduce.map.memory.mb=3072
hdfs\:dfs.datanode.address=0.0.0.0\:9866
yarn-env\:YARN_RESOURCEMANAGER_HEAPSIZE=1920
yarn\:yarn.scheduler.minimum-allocation-mb=1
dataproc\:dataproc.worker.custom.init.actions.mode=RUN_BEFORE_SERVICES
spark\:spark.ui.port=0
spark\:spark.driver.maxResultSize=960m
dataproc\:dataproc.monitoring.stackdriver.enable=false
spark\:spark.executor.instances=2
mapred-env\:HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1920
hdfs\:dfs.namenode.handler.count=20
hdfs\:dfs.datanode.https.address=0.0.0.0\:9865
yarn\:yarn.nodemanager.address=0.0.0.0\:8026
distcp\:mapreduce.reduce.memory.mb=768
dataproc\:dataproc.heartbeat.master.frequency.sec=30
spark\:spark.executor.memory=2688m
hdfs\:dfs.datanode.ipc.address=0.0.0.0\:9867
mapred\:mapreduce.reduce.java.opts=-Xmx2457m
mapred\:mapreduce.map.java.opts=-Xmx2457m
yarn\:yarn.nodemanager.resource.cpu-vcores=2
hdfs\:dfs.namenode.secondary.https-address=0.0.0.0\:9869
hdfs\:dfs.datanode.http.address=0.0.0.0\:9864
hdfs\:dfs.namenode.http-address=0.0.0.0\:9870
core\:fs.gs.block.size=134217728
core\:hadoop.ssl.enabled.protocols=TLSv1,TLSv1.1,TLSv1.2
hdfs\:dfs.namenode.lifeline.rpc-address=student-01-71e17b39d43c-qwiklab-m\:8050
mapred\:mapreduce.map.cpu.vcores=1
dataproc\:dataproc.conscrypt.provider.enable=true
hdfs\:dfs.namenode.servicerpc-address=student-01-71e17b39d43c-qwiklab-m\:8051
distcp\:mapreduce.reduce.java.opts=-Xmx576m
yarn\:yarn.nodemanager.resource.memory-mb=6144
spark\:spark.yarn.am.memory=640m
dataproc\:dataproc.job.metrics.monitor.interval.sec=60
dataproc\:dataproc.control.task.invalidation.interval.millis=5000
hive\:hive.fetch.task.conversion=none
dataproc\:job.history.to-gcs.enabled=true
dataproc\:yarn.log-aggregation.enabled=true
mapred\:mapreduce.job.reduces=3
spark\:spark.scheduler.mode=FAIR
dataproc\:dataproc.scheduler.max-memory-used=0.9
hdfs\:dfs.namenode.https-address=0.0.0.0\:9871
dataproc\:simplified.scaling.enable=true
yarn-env\:YARN_TIMELINESERVER_HEAPSIZE=1920
mapred\:mapreduce.job.maps=9
dataproc\:dataproc.control.task.stream.duration.sec=600
dataproc\:am.primary_only=false
spark\:spark.sql.cbo.enabled=true
dataproc\:dataproc.master.custom.init.actions.mode=RUN_BEFORE_SERVICES
mapred\:mapreduce.job.reduce.slowstart.completedmaps=0.95
core\:fs.gs.metadata.cache.enable=false
spark\:spark.driver.memory=1920m
yarn\:yarn.scheduler.maximum-allocation-mb=6144
capacity-scheduler\:yarn.scheduler.capacity.root.default.ordering-policy=fair
distcp\:mapreduce.map.memory.mb=768
mapred\:mapreduce.task.io.sort.mb=256
